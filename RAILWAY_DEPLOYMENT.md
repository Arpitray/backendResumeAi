# ğŸš‚ Railway Deployment Guide

## âœ… Persistence Fixed

### What Was The Problem?
Previously, the app used `chromadb.Client()` with `Settings(persist_directory=...)`, which could lose data on restart in some environments.

### The Fix
Now using `chromadb.PersistentClient()` which:
- âœ… Auto-persists all data to disk immediately
- âœ… Survives container restarts
- âœ… Works reliably on Railway, Render, and other platforms

### Technical Details
```python
# OLD (could lose data)
_chroma = chromadb.Client(
    Settings(persist_directory="./vector_store")
)

# NEW (guaranteed persistence)
_chroma = chromadb.PersistentClient(
    path="./vector_store",
    settings=Settings(anonymized_telemetry=False)
)
```

### Verification
After uploading a resume, check the logs:
```
ğŸ’¾ Data will auto-persist to ./vector_store
ğŸ“¦ Collection count after add: 12
âœ… store_chunks() complete
```

---

## ğŸš€ Railway Deployment Checklist

### 1. Environment Variables
Set these in Railway dashboard:

```bash
# Required
REDIS_URL=redis://your-redis-url:6379

# Optional (if using external LLM APIs)
OPENAI_API_KEY=your-key-here
ANTHROPIC_API_KEY=your-key-here
```

### 2. Volume Mount (CRITICAL for persistence)
Railway needs a volume mount for the vector_store to survive deployments:

**In Railway Dashboard:**
1. Go to your service â†’ **Variables** tab
2. Add a **Volume Mount**:
   - **Mount Path**: `/app/vector_store`
   - **Size**: 1GB (adjust based on your needs)

This ensures uploaded resumes and job descriptions persist across deploys.

### 3. Start Command
Railway should auto-detect from `Procfile`:
```
web: uvicorn server:app --host 0.0.0.0 --port $PORT
```

Or set manually in Railway:
```bash
uvicorn server:app --host 0.0.0.0 --port $PORT
```

### 4. Health Check
Railway will hit `/` endpoint:
```json
{"status": "AI Career Agent running"}
```

---

## ğŸ“Š File Structure After Deploy

```
/app/
â”œâ”€â”€ server.py
â”œâ”€â”€ memory.py
â”œâ”€â”€ core_match.py
â”œâ”€â”€ vector_store/          # â† Persisted (with volume mount)
â”‚   â”œâ”€â”€ chroma.sqlite3     # â† ChromaDB database
â”‚   â””â”€â”€ index/             # â† Vector indices
â””â”€â”€ uploads/               # â† Temp PDF storage (optional persistence)
```

---

## ğŸ› Troubleshooting

### "Resume not found" after restart
**Cause:** Volume not mounted  
**Fix:** Add volume mount in Railway settings (see above)

### Redis connection errors
**Cause:** `REDIS_URL` not set  
**Fix:** Add Redis add-on in Railway or use external Redis

### Slow first request
**Normal:** Chroma loads the vector index on first access (1-2s)  
**After first load:** Fast lookups

---

## ğŸ§ª Testing Persistence Locally

```bash
# 1. Upload a resume
curl -X POST http://localhost:8000/upload-resume \
  -F "file=@resume.pdf"

# Response: {"stored_as": "abc-123.pdf", ...}

# 2. Restart server
# Ctrl+C then: uvicorn server:app --reload

# 3. Try matching (should still work!)
curl -X POST http://localhost:8000/match \
  -H "Content-Type: application/json" \
  -d '{"resume_id": "abc-123.pdf", "job_id": "xyz"}'
```

If it returns match results â†’ âœ… Persistence works!

---

## ğŸ“ˆ Monitoring

### Check Vector Store Size
```bash
# On Railway shell
du -sh /app/vector_store
```

### Check Collection Count
```python
from memory import get_collection
col = get_collection()
print(f"Total vectors: {col.count()}")
```

---

## ğŸ” Security Notes

1. **uploads/** folder contains user PDFs
   - Consider using cloud storage (S3/Cloudinary) for production
   - Or mount a volume and clean periodically

2. **vector_store/** contains embeddings only
   - Original text is chunked but not sensitive
   - No PII stored unless in resumes themselves

3. **Redis cache** expires after 15 minutes
   - Consider shorter TTL for sensitive data
   - Or don't cache match results (only cache AI analysis)

---

## ğŸ’¡ Production Recommendations

### For High Traffic
1. Use Railway's **horizontal scaling**
2. Add a load balancer
3. Use **PostgreSQL + pgvector** instead of ChromaDB file-based storage

### For Cost Optimization
1. Lazy-load embedding models (already implemented)
2. Cache aggressively (already implemented)
3. Use Railway's sleep mode for non-peak hours

### For Better UX
1. Add WebSocket for live progress updates
2. Stream LLM responses instead of waiting
3. Pre-compute popular job matches

---

## âœ… Deployment Verified

- âœ… PersistentClient configured
- âœ… Auto-persistence enabled
- âœ… Redis caching implemented
- âœ… Parallel LLM calls optimized
- âœ… Ready for Railway deployment

**Next Step:** Push to GitHub, connect Railway, add volume mount, deploy! ğŸš€
